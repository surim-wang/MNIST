ocr 구축하는 방법 머리속에 떠오른 생각
1단계
1. MNIST를 통해 이미지를 텍스트로 바꾸는 연습을 해보자.

2단계
2. 같은 환경에서 촬영한 데이터를 4000장을 찍어보자.
** 사진데이터에서 글자들을 추출하기전에 사진을 스캔한거마냥 깔끔하게 정리하는 기능이 있어야 좋은 라벨링을 할 수 있을까?
3. 이미지 처리를 통해 사진 속의 글자들을 하나하나 훈련 데이터로 변환을 하자. (여기가 시간 무지하게 많이 걸릴듯)
- 사진 불러오기
- 그레이 스케일로 변환(등등)
- 이미지 자르기
- 이미지 사이즈 통일 시키기 (28*28)
: 이미지를 축소하거나 확대할텐데 이미지 변조가 일어나면 해석이 제대로 될까?
- 만들어진 이미지들을 분석을 위해 (x, 784)형태로 변형하기

3단계
4. 만들어진 데이터로 OCR 기능을 구현해 보자.
5. 한 페이지에 대해서 ocr 성능 80% 이상으로 끌어 올리기
6. 모든 데이터로(병원 기록) 훈련데이터와 테스트 데이터로 구분하기
7. 최종 모델을 만들어보자

4단계(여기부터는 아직 어떻게 해야할지 감은 잘 안옴)
8. 만들어진 모델(알고리즘)로 사진에서 바로 적용하는 방법 생각 해보기.
-사진에서 바로 접목하려면 폰트의 크기가 다른데 가능한지? 
-표의 형태로 되어 있는데 가능할지? 여기서부터는 이스트소프트 논문 참고해야할듯.
